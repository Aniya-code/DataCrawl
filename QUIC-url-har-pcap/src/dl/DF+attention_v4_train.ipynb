{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(379, 100)\n",
      "(220, 100)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "import ast\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "# # 设置CUDA_VISIBLE_DEVICES环境变量\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "seed = 11415\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "Desired_Length = 100\n",
    "batch_size = 16\n",
    "class YtData(object):\n",
    "\n",
    "    def __init__(self, batch_size, file_name1, file_name2):\n",
    "        data1 = pd.read_csv(file_name1, header=None)\n",
    "        data2 = pd.read_csv(file_name2, header=None)\n",
    "        self.desired_length = Desired_Length\n",
    "        \n",
    "        \n",
    "        self._encoder = {\n",
    "            'label':    LabelEncoder()\n",
    "        }\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        target = np.array(data1.iloc[:, 0])\n",
    "        features = data1.iloc[:, -1]\n",
    "        features = features.apply(lambda x: [int(float(i)) for i in x.split('/') if i]).to_list()\n",
    "        features = np.array([self.pad_or_truncate(lst) for lst in features])\n",
    "\n",
    "        features = np.array(features)\n",
    "        data = np.array(features)\n",
    "        data = np.array(data)\n",
    "        data = np.abs(data)\n",
    "        print(data.shape)\n",
    "\n",
    "\n",
    "        data_X, data_y = self.__encode_data(data, target)\n",
    "        self.train_dataset = TensorDataset(\n",
    "            torch.from_numpy(data_X.astype(np.float32)),\n",
    "            torch.from_numpy(data_y.astype(np.int64))\n",
    "        )\n",
    "\n",
    "        target = np.array(data2.iloc[:, 0])\n",
    "        features = data2.iloc[:, -1]\n",
    "        features = features.apply(lambda x: [int(float(i)) for i in x.split('/') if i]).to_list()\n",
    "        features = np.array([self.pad_or_truncate(lst) for lst in features])\n",
    "\n",
    "        features = np.array(features)\n",
    "        data = np.array(features)\n",
    "        data = np.array(data)\n",
    "        data = np.abs(data)\n",
    "        print(data.shape)\n",
    "\n",
    "        \n",
    "        data_X, data_y = self.__encode_data(data, target)\n",
    "        self.test_dataset = TensorDataset(\n",
    "            torch.from_numpy(data_X.astype(np.float32)),\n",
    "            torch.from_numpy(data_y.astype(np.int64))\n",
    "        )\n",
    "\n",
    " \n",
    "        self.train_dataloader = DataLoader(self.train_dataset, self.batch_size, shuffle=True)\n",
    "        self.test_dataloader = DataLoader(self.test_dataset, self.batch_size, shuffle=True)\n",
    "\n",
    "    def pad_or_truncate(self, lst):\n",
    "        if len(lst) < self.desired_length:\n",
    "            return lst + [0] * (self.desired_length - len(lst))\n",
    "        else:\n",
    "            return lst[:self.desired_length]\n",
    "        \n",
    "    def __encode_data(self, data_X, data_y):\n",
    "        label_encoder = self._encoder['label']\n",
    "        # 保存 label_encoder 到文件\n",
    "        label_encoder.fit(list(set(data_y)))\n",
    "        with open('label_encoder.pkl', 'wb') as file:\n",
    "            pickle.dump(label_encoder, file)\n",
    "\n",
    "        # 获取标签和对应的数值\n",
    "        label_to_num = {label: idx for idx, label in enumerate(label_encoder.classes_)}\n",
    "\n",
    "        # 保存到 JSON 文件\n",
    "        with open('label_encoder.json', 'w') as file:\n",
    "            json.dump(label_to_num, file)\n",
    "\n",
    "        data_X = np.pad(data_X, ((0, 0), (0, self.desired_length - len(data_X[0]))), 'constant').reshape(-1, 1, self.desired_length)\n",
    "        data_y = label_encoder.transform(data_y)\n",
    "        return data_X, data_y\n",
    "\n",
    "    \"\"\"将数据拆分为训练集和测试集，并转换为TensorDataset对象\"\"\"\n",
    "    def __split_data_to_tensor(self, data_X, data_y):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data_X, data_y, test_size=0.3)\n",
    "        train_dataset = TensorDataset(\n",
    "            torch.from_numpy(X_train.astype(np.float32)),\n",
    "            torch.from_numpy(y_train.astype(np.int64))\n",
    "        )\n",
    "        test_dataset = TensorDataset(\n",
    "            torch.from_numpy(X_test.astype(np.float32)),\n",
    "            torch.from_numpy(y_test.astype(np.int64))\n",
    "        )\n",
    "        return train_dataset, test_dataset\n",
    "\n",
    "\n",
    "dataset = YtData(batch_size, r'E:\\ZLJ_code\\yt-url-har-pcap\\data\\quic_chunk\\train_chunk.csv', r'E:\\ZLJ_code\\yt-url-har-pcap\\data\\quic_chunk\\test_chunk.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 39.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish 1 epoch, Loss: 5.359348, Acc: 0.002639\n",
      "Validation Loss: 82.613076, Acc: 0.071429\n",
      "epoch 2\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 40.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish 2 epoch, Loss: 5.206365, Acc: 0.015831\n",
      "Validation Loss: 82.118307, Acc: 0.000000\n",
      "epoch 3\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 41.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish 3 epoch, Loss: 5.095560, Acc: 0.018470\n",
      "Validation Loss: 82.026542, Acc: 0.000000\n",
      "epoch 4\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 36.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish 4 epoch, Loss: 4.992971, Acc: 0.026385\n",
      "Validation Loss: 81.574766, Acc: 0.142857\n",
      "epoch 5\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 38.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish 5 epoch, Loss: 4.928925, Acc: 0.044855\n",
      "Validation Loss: 81.402228, Acc: 0.071429\n",
      "epoch 6\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 37.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish 6 epoch, Loss: 4.850379, Acc: 0.058047\n",
      "Validation Loss: 80.930936, Acc: 0.142857\n",
      "epoch 7\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 38.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish 7 epoch, Loss: 4.763184, Acc: 0.060686\n",
      "Validation Loss: 80.687536, Acc: 0.357143\n",
      "epoch 8\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 39.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish 8 epoch, Loss: 4.701479, Acc: 0.092348\n",
      "Validation Loss: 80.769786, Acc: 0.071429\n",
      "epoch 9\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 39.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish 9 epoch, Loss: 4.594361, Acc: 0.121372\n",
      "Validation Loss: 80.541719, Acc: 0.142857\n",
      "epoch 10\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 40.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish 10 epoch, Loss: 4.551549, Acc: 0.102902\n",
      "Validation Loss: 80.403694, Acc: 0.000000\n",
      "epoch 11\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 35.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish 11 epoch, Loss: 4.443057, Acc: 0.131926\n",
      "Validation Loss: 80.417292, Acc: 0.214286\n",
      "epoch 12\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 39.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish 12 epoch, Loss: 4.388747, Acc: 0.142480\n",
      "Validation Loss: 80.208597, Acc: 0.142857\n",
      "epoch 13\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 39.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish 13 epoch, Loss: 4.331512, Acc: 0.163588\n",
      "Validation Loss: 80.220732, Acc: 0.214286\n",
      "epoch 14\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 40.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish 14 epoch, Loss: 4.231518, Acc: 0.205805\n",
      "Validation Loss: 79.715177, Acc: 0.142857\n",
      "epoch 15\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 39.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish 15 epoch, Loss: 4.177845, Acc: 0.189974\n",
      "Validation Loss: 79.712695, Acc: 0.285714\n",
      "epoch 16\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 41.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish 16 epoch, Loss: 4.072469, Acc: 0.253298\n",
      "Validation Loss: 79.424798, Acc: 0.357143\n",
      "epoch 17\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 39.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish 17 epoch, Loss: 4.021356, Acc: 0.277045\n",
      "Validation Loss: 79.903173, Acc: 0.142857\n",
      "epoch 18\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 40.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish 18 epoch, Loss: 3.972945, Acc: 0.292876\n",
      "Validation Loss: 79.859862, Acc: 0.285714\n",
      "epoch 19\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 39.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish 19 epoch, Loss: 3.930997, Acc: 0.271768\n",
      "Validation Loss: 80.029800, Acc: 0.357143\n",
      "epoch 20\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 39.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish 20 epoch, Loss: 3.842627, Acc: 0.319261\n",
      "Validation Loss: 79.613483, Acc: 0.285714\n",
      "epoch 21\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 39.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish 21 epoch, Loss: 3.769375, Acc: 0.319261\n",
      "Validation Loss: 79.339731, Acc: 0.357143\n",
      "epoch 22\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 40.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish 22 epoch, Loss: 3.714817, Acc: 0.361478\n",
      "Validation Loss: 79.315769, Acc: 0.428571\n",
      "epoch 23\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 33.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish 23 epoch, Loss: 3.623687, Acc: 0.424802\n",
      "Validation Loss: 79.110590, Acc: 0.357143\n",
      "epoch 24\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 40.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish 24 epoch, Loss: 3.574956, Acc: 0.416887\n",
      "Validation Loss: 79.095878, Acc: 0.428571\n",
      "epoch 25\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 39.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish 25 epoch, Loss: 3.510256, Acc: 0.451187\n",
      "Validation Loss: 79.162334, Acc: 0.428571\n",
      "epoch 26\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 40.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish 26 epoch, Loss: 3.436777, Acc: 0.440633\n",
      "Validation Loss: 79.156963, Acc: 0.428571\n",
      "epoch 27\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 39.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish 27 epoch, Loss: 3.374279, Acc: 0.459103\n",
      "Validation Loss: 79.211061, Acc: 0.285714\n",
      "epoch 28\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 39.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish 28 epoch, Loss: 3.334465, Acc: 0.488127\n",
      "Validation Loss: 79.438284, Acc: 0.357143\n",
      "epoch 29\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 40.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish 29 epoch, Loss: 3.276384, Acc: 0.503958\n",
      "Validation Loss: 79.187579, Acc: 0.285714\n",
      "epoch 30\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 38.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish 30 epoch, Loss: 3.202941, Acc: 0.530343\n",
      "Validation Loss: 79.473958, Acc: 0.357143\n",
      "epoch 31\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 39.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish 31 epoch, Loss: 3.104949, Acc: 0.601583\n",
      "Validation Loss: 79.123076, Acc: 0.357143\n",
      "epoch 32\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 39.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish 32 epoch, Loss: 3.066061, Acc: 0.567282\n",
      "Validation Loss: 79.265842, Acc: 0.428571\n",
      "epoch 33\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 37.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish 33 epoch, Loss: 2.982900, Acc: 0.588391\n",
      "Validation Loss: 79.259558, Acc: 0.285714\n",
      "epoch 34\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 39.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish 34 epoch, Loss: 2.931835, Acc: 0.609499\n",
      "Validation Loss: 79.032227, Acc: 0.428571\n",
      "epoch 35\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 39.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish 35 epoch, Loss: 2.876575, Acc: 0.630607\n",
      "Validation Loss: 79.120670, Acc: 0.357143\n",
      "epoch 36\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 39.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish 36 epoch, Loss: 2.830942, Acc: 0.643799\n",
      "Validation Loss: 79.294799, Acc: 0.357143\n",
      "epoch 37\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 38.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish 37 epoch, Loss: 2.735603, Acc: 0.643799\n",
      "Validation Loss: 79.142222, Acc: 0.428571\n",
      "epoch 38\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 39.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish 38 epoch, Loss: 2.668643, Acc: 0.680739\n",
      "Validation Loss: 79.143026, Acc: 0.357143\n",
      "epoch 39\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 41.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish 39 epoch, Loss: 2.627559, Acc: 0.691293\n",
      "Validation Loss: 78.963112, Acc: 0.357143\n",
      "epoch 40\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 38.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish 40 epoch, Loss: 2.559274, Acc: 0.701847\n",
      "Validation Loss: 79.564207, Acc: 0.357143\n",
      "epoch 41\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 39.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish 41 epoch, Loss: 2.479206, Acc: 0.733509\n",
      "Validation Loss: 78.993339, Acc: 0.285714\n",
      "epoch 42\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 39.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish 42 epoch, Loss: 2.438726, Acc: 0.725594\n",
      "Validation Loss: 78.922773, Acc: 0.428571\n",
      "Early stopping\n",
      "Model saved in ONNX format at E:\\ZLJ_code\\yt-url-har-pcap\\data\\model\\model_p100.onnx\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# 设置CUDA_VISIBLE_DEVICES环境变量为0，这将使得CUDA程序只能看到第0个GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# 神经网络参数\n",
    "batch_size = 16\n",
    "learning_rate = 1e-2\n",
    "num_epoches = 100\n",
    "USE_GPU = False\n",
    "num_class = 191\n",
    "\n",
    "# 定义Self-Attention模块\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, in_dim):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.query_conv = nn.Conv1d(in_dim, in_dim // 8, kernel_size=1)\n",
    "        self.key_conv = nn.Conv1d(in_dim, in_dim // 8, kernel_size=1)\n",
    "        self.value_conv = nn.Conv1d(in_dim, in_dim, kernel_size=1)\n",
    "        self.gamma = nn.Parameter(torch.zeros(1))\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, C, width = x.size()\n",
    "        query = self.query_conv(x).view(batch_size, -1, width).permute(0, 2, 1)\n",
    "        key = self.key_conv(x).view(batch_size, -1, width)\n",
    "        energy = torch.bmm(query, key)\n",
    "        attention = self.softmax(energy)\n",
    "        value = self.value_conv(x).view(batch_size, -1, width)\n",
    "        out = torch.bmm(value, attention.permute(0, 2, 1))\n",
    "        out = out.view(batch_size, C, width)\n",
    "        out = self.gamma * out + x\n",
    "        return out\n",
    "\n",
    "# 定义包含Self-Attention的CNN模型\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, in_dim, num_class):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Sequential(       \n",
    "            nn.Conv1d(1, 32, 5, 1, 2),\n",
    "            nn.BatchNorm1d(32), \n",
    "            nn.ELU(),                     \n",
    "            nn.Conv1d(32, 32, 5, 1, 2),\n",
    "            nn.BatchNorm1d(32), \n",
    "            nn.ELU(),           \n",
    "            nn.MaxPool1d(3, 3, 0),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "        self.attention1 = SelfAttention(32)\n",
    "\n",
    "        self.conv2 = nn.Sequential(       \n",
    "            nn.Conv1d(32, 64, 5, 1, 2),\n",
    "            nn.BatchNorm1d(64), \n",
    "            nn.ReLU(),                     \n",
    "            nn.Conv1d(64, 64, 5, 1, 2),\n",
    "            nn.BatchNorm1d(64), \n",
    "            nn.ReLU(),           \n",
    "            nn.MaxPool1d(3, 3, 0),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "        self.attention2 = SelfAttention(64)\n",
    "\n",
    "        self.out1 = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(704, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "        self.out2 = nn.Sequential(\n",
    "            nn.Linear(256, num_class)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.attention1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.attention2(x)\n",
    "        output = self.out1(x)\n",
    "        output = self.out2(output)\n",
    "        return output\n",
    "\n",
    "# 实例化模型\n",
    "model = CNN(in_dim=1, num_class=191)\n",
    "\n",
    "def train():\n",
    "    global model\n",
    "    best_acc = 0.0\n",
    "    patience = 20\n",
    "    patience_counter = 0\n",
    "\n",
    "    if USE_GPU:\n",
    "        model = model.cuda()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in range(num_epoches):\n",
    "        print('epoch {}'.format(epoch + 1))\n",
    "        print('*' * 10)\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "        model.train()  # 设置模型为训练模式\n",
    "        for i, data in tqdm(enumerate(dataset.train_dataloader, 1)):\n",
    "            img, label = data\n",
    "            if USE_GPU:\n",
    "                img = img.cuda()\n",
    "                label = label.cuda()\n",
    "            img = Variable(img)\n",
    "            label = Variable(label)\n",
    "            # 向前传播\n",
    "            out = model(img)\n",
    "            loss = criterion(out, label)\n",
    "            running_loss += loss.item() * label.size(0)\n",
    "            _, pred = torch.max(out, 1)\n",
    "            num_correct = (pred == label).sum()\n",
    "            accuracy = (pred == label).float().mean()\n",
    "            running_acc += num_correct.item()\n",
    "            # 向后传播\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print('Finish {} epoch, Loss: {:.6f}, Acc: {:.6f}'.format(\n",
    "            epoch + 1, running_loss / (len(dataset.train_dataset)), running_acc / (len(\n",
    "                dataset.train_dataset))))\n",
    "        \n",
    "        model.eval()  # 设置模型为评估模式\n",
    "        eval_loss = 0.0\n",
    "        eval_acc = 0.0\n",
    "        for data in dataset.test_dataloader:\n",
    "            img, label = data\n",
    "            if USE_GPU:\n",
    "                img = img.cuda()\n",
    "                label = label.cuda()\n",
    "            with torch.no_grad():\n",
    "                out = model(img)\n",
    "                loss = criterion(out, label)\n",
    "            eval_loss += loss.item() * label.size(0)\n",
    "            _, pred = torch.max(out, 1)\n",
    "            num_correct = (pred == label).sum()\n",
    "            eval_acc += num_correct.item()\n",
    "        print('Validation Loss: {:.6f}, Acc: {:.6f}'.format(\n",
    "            eval_loss / (len(dataset.test_dataloader)), eval_acc / (len(dataset.test_dataloader))))\n",
    "        \n",
    "        # 保存最好的模型\n",
    "        if eval_acc > best_acc:\n",
    "            best_acc = eval_acc\n",
    "            torch.save(model.state_dict(), r'E:\\ZLJ_code\\yt-url-har-pcap\\data\\model\\model_p100.pth')\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            # 如果验证准确率在10个epoch内没有提高，停止训练\n",
    "            if patience_counter >= patience:\n",
    "                print('Early stopping')\n",
    "                break\n",
    "\n",
    "train()\n",
    "\n",
    "# 创建一个示例输入张量，假设输入为单通道1D数据\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "dummy_input = torch.randn(batch_size, 1, 100)  # 调整为符合实际输入维度\n",
    "dummy_input = dummy_input.to(device)\n",
    "\n",
    "# 保存为ONNX格式\n",
    "onnx_model_path = r\"E:\\ZLJ_code\\yt-url-har-pcap\\data\\model\\model_p100.onnx\"\n",
    "torch.onnx.export(model, dummy_input, onnx_model_path,\n",
    "                  input_names=['input'], output_names=['output'],\n",
    "                  dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}})\n",
    "\n",
    "print(f\"Model saved in ONNX format at {onnx_model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 3 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 2 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.5000    0.6667         2\n",
      "           1     0.0000    0.0000    0.0000         1\n",
      "           2     0.2727    1.0000    0.4286         3\n",
      "           3     1.0000    0.5000    0.6667         2\n",
      "           4     1.0000    0.3333    0.5000         3\n",
      "           5     0.0000    0.0000    0.0000         2\n",
      "           6     1.0000    0.6667    0.8000         3\n",
      "           7     0.0000    0.0000    0.0000         1\n",
      "           8     1.0000    0.5000    0.6667         2\n",
      "           9     1.0000    1.0000    1.0000         1\n",
      "          10     0.0000    0.0000    0.0000         1\n",
      "          11     1.0000    0.5000    0.6667         2\n",
      "          12     0.0000    0.0000    0.0000         2\n",
      "          13     0.5000    0.7500    0.6000         4\n",
      "          14     1.0000    1.0000    1.0000         2\n",
      "          15     1.0000    0.5000    0.6667         2\n",
      "          16     1.0000    1.0000    1.0000         2\n",
      "          17     1.0000    0.5000    0.6667         2\n",
      "          18     1.0000    0.5000    0.6667         2\n",
      "          19     0.0000    0.0000    0.0000         2\n",
      "          20     0.4000    0.5000    0.4444         4\n",
      "          21     0.6000    1.0000    0.7500         3\n",
      "          22     1.0000    1.0000    1.0000         2\n",
      "          23     1.0000    0.5000    0.6667         2\n",
      "          24     0.0000    0.0000    0.0000         2\n",
      "          25     1.0000    0.6667    0.8000         3\n",
      "          26     0.2000    0.6667    0.3077         3\n",
      "          27     1.0000    1.0000    1.0000         2\n",
      "          28     1.0000    0.5000    0.6667         2\n",
      "          29     0.5000    1.0000    0.6667         2\n",
      "          30     0.6667    1.0000    0.8000         2\n",
      "          31     1.0000    1.0000    1.0000         2\n",
      "          32     1.0000    1.0000    1.0000         2\n",
      "          33     0.0000    0.0000    0.0000         1\n",
      "          34     1.0000    1.0000    1.0000         2\n",
      "          35     0.6000    1.0000    0.7500         3\n",
      "          36     0.7500    1.0000    0.8571         3\n",
      "          37     1.0000    0.6667    0.8000         3\n",
      "          38     1.0000    0.5000    0.6667         2\n",
      "          39     1.0000    1.0000    1.0000         2\n",
      "          40     0.1429    1.0000    0.2500         6\n",
      "          41     1.0000    0.5000    0.6667         2\n",
      "          42     0.3333    1.0000    0.5000         4\n",
      "          43     1.0000    0.5000    0.6667         2\n",
      "          44     0.0000    0.0000    0.0000         2\n",
      "          45     1.0000    1.0000    1.0000         2\n",
      "          46     0.0000    0.0000    0.0000         1\n",
      "          47     1.0000    0.6667    0.8000         3\n",
      "          48     0.4000    1.0000    0.5714         2\n",
      "          49     0.0000    0.0000    0.0000         1\n",
      "          50     0.6667    0.6667    0.6667         3\n",
      "          51     0.0000    0.0000    0.0000         1\n",
      "          52     0.0000    0.0000    0.0000         1\n",
      "          53     1.0000    0.5000    0.6667         2\n",
      "          54     0.0000    0.0000    0.0000         1\n",
      "          55     1.0000    0.5000    0.6667         2\n",
      "          56     0.0000    0.0000    0.0000         1\n",
      "          57     1.0000    0.5000    0.6667         2\n",
      "          58     0.6667    1.0000    0.8000         2\n",
      "          59     0.2857    1.0000    0.4444         2\n",
      "          60     1.0000    0.5000    0.6667         2\n",
      "          61     1.0000    0.6667    0.8000         3\n",
      "          62     1.0000    1.0000    1.0000         1\n",
      "          63     0.0000    0.0000    0.0000         2\n",
      "          64     1.0000    0.6667    0.8000         3\n",
      "          65     1.0000    1.0000    1.0000         2\n",
      "          66     1.0000    1.0000    1.0000         1\n",
      "          67     0.0000    0.0000    0.0000         1\n",
      "          68     1.0000    1.0000    1.0000         2\n",
      "          69     1.0000    0.5000    0.6667         2\n",
      "          70     1.0000    0.5000    0.6667         2\n",
      "          71     1.0000    1.0000    1.0000         2\n",
      "          72     0.0000    0.0000    0.0000         1\n",
      "          73     0.0000    0.0000    0.0000         2\n",
      "          74     0.5000    0.5000    0.5000         2\n",
      "          75     1.0000    0.5000    0.6667         2\n",
      "          76     1.0000    0.5000    0.6667         2\n",
      "          77     1.0000    0.5000    0.6667         2\n",
      "          78     1.0000    1.0000    1.0000         2\n",
      "          79     1.0000    1.0000    1.0000         2\n",
      "          80     1.0000    1.0000    1.0000         3\n",
      "          81     0.0000    0.0000    0.0000         1\n",
      "          82     1.0000    1.0000    1.0000         2\n",
      "          83     1.0000    0.5000    0.6667         2\n",
      "          84     1.0000    1.0000    1.0000         2\n",
      "          85     0.0000    0.0000    0.0000         1\n",
      "          86     1.0000    0.5000    0.6667         2\n",
      "          87     0.0000    0.0000    0.0000         1\n",
      "          88     1.0000    0.6667    0.8000         3\n",
      "          89     1.0000    0.5000    0.6667         2\n",
      "          90     1.0000    1.0000    1.0000         2\n",
      "          91     0.0000    0.0000    0.0000         1\n",
      "          92     0.0000    0.0000    0.0000         1\n",
      "          93     1.0000    1.0000    1.0000         2\n",
      "          94     0.0000    0.0000    0.0000         1\n",
      "          95     0.0000    0.0000    0.0000         1\n",
      "          96     1.0000    1.0000    1.0000         2\n",
      "          97     0.0000    0.0000    0.0000         2\n",
      "          98     1.0000    0.5000    0.6667         2\n",
      "          99     0.5000    0.6667    0.5714         3\n",
      "         100     1.0000    1.0000    1.0000         1\n",
      "         101     1.0000    1.0000    1.0000         2\n",
      "         102     0.0000    0.0000    0.0000         2\n",
      "         103     1.0000    1.0000    1.0000         1\n",
      "         104     0.0000    0.0000    0.0000         2\n",
      "         105     0.2857    1.0000    0.4444         2\n",
      "         106     0.0000    0.0000    0.0000         1\n",
      "         107     0.0000    0.0000    0.0000         2\n",
      "         108     0.0000    0.0000    0.0000         1\n",
      "         109     1.0000    1.0000    1.0000         2\n",
      "         110     1.0000    0.5000    0.6667         2\n",
      "         111     1.0000    0.5000    0.6667         2\n",
      "         112     1.0000    0.5000    0.6667         2\n",
      "         113     0.0000    0.0000    0.0000         1\n",
      "         114     0.0000    0.0000    0.0000         1\n",
      "         115     1.0000    0.5000    0.6667         2\n",
      "         116     0.0000    0.0000    0.0000         1\n",
      "         117     1.0000    1.0000    1.0000         2\n",
      "         118     1.0000    0.2500    0.4000         4\n",
      "         119     1.0000    1.0000    1.0000         2\n",
      "         120     1.0000    0.5000    0.6667         2\n",
      "         121     1.0000    1.0000    1.0000         2\n",
      "         122     1.0000    0.5000    0.6667         2\n",
      "         123     0.0000    0.0000    0.0000         1\n",
      "         124     0.2857    1.0000    0.4444         2\n",
      "         125     0.0000    0.0000    0.0000         2\n",
      "         126     1.0000    1.0000    1.0000         2\n",
      "         127     0.6000    1.0000    0.7500         3\n",
      "         128     0.0000    0.0000    0.0000         2\n",
      "         129     0.0000    0.0000    0.0000         1\n",
      "         130     1.0000    1.0000    1.0000         2\n",
      "         131     1.0000    0.5000    0.6667         2\n",
      "         132     0.6667    1.0000    0.8000         2\n",
      "         133     0.4286    1.0000    0.6000         3\n",
      "         134     1.0000    0.5000    0.6667         2\n",
      "         135     1.0000    0.5000    0.6667         2\n",
      "         136     0.0000    0.0000    0.0000         1\n",
      "         137     1.0000    1.0000    1.0000         1\n",
      "         138     1.0000    1.0000    1.0000         2\n",
      "         139     0.3333    0.3333    0.3333         3\n",
      "         140     0.6000    1.0000    0.7500         3\n",
      "         141     1.0000    1.0000    1.0000         3\n",
      "         142     0.0000    0.0000    0.0000         1\n",
      "         143     1.0000    1.0000    1.0000         2\n",
      "         144     1.0000    0.5000    0.6667         2\n",
      "         145     1.0000    0.5000    0.6667         2\n",
      "         146     1.0000    1.0000    1.0000         2\n",
      "         147     1.0000    1.0000    1.0000         2\n",
      "         148     0.5000    0.5000    0.5000         2\n",
      "         149     0.1667    0.5000    0.2500         2\n",
      "         150     1.0000    1.0000    1.0000         2\n",
      "         151     1.0000    0.5000    0.6667         2\n",
      "         152     0.0000    0.0000    0.0000         2\n",
      "         153     1.0000    1.0000    1.0000         2\n",
      "         154     1.0000    1.0000    1.0000         2\n",
      "         155     1.0000    0.5000    0.6667         2\n",
      "         156     1.0000    1.0000    1.0000         2\n",
      "         157     1.0000    1.0000    1.0000         2\n",
      "         158     0.6667    1.0000    0.8000         2\n",
      "         159     0.5000    0.5000    0.5000         2\n",
      "         160     0.0000    0.0000    0.0000         1\n",
      "         161     1.0000    1.0000    1.0000         2\n",
      "         162     1.0000    0.6667    0.8000         3\n",
      "         163     1.0000    1.0000    1.0000         3\n",
      "         164     1.0000    1.0000    1.0000         2\n",
      "         165     1.0000    0.5000    0.6667         2\n",
      "         166     0.5000    0.5000    0.5000         2\n",
      "         167     0.0000    0.0000    0.0000         1\n",
      "         168     0.0000    0.0000    0.0000         1\n",
      "         169     1.0000    1.0000    1.0000         2\n",
      "         170     0.0000    0.0000    0.0000         1\n",
      "         171     1.0000    1.0000    1.0000         2\n",
      "         172     0.0000    0.0000    0.0000         1\n",
      "         173     1.0000    0.5000    0.6667         2\n",
      "         174     0.5000    0.7500    0.6000         4\n",
      "         175     1.0000    0.5000    0.6667         2\n",
      "         176     0.0000    0.0000    0.0000         2\n",
      "         177     0.2143    0.7500    0.3333         4\n",
      "         178     0.0000    0.0000    0.0000         1\n",
      "         179     1.0000    1.0000    1.0000         2\n",
      "         180     0.4000    1.0000    0.5714         2\n",
      "         181     1.0000    1.0000    1.0000         2\n",
      "         182     0.0000    0.0000    0.0000         2\n",
      "         183     1.0000    1.0000    1.0000         1\n",
      "         184     0.6667    0.6667    0.6667         3\n",
      "         185     0.0000    0.0000    0.0000         1\n",
      "         186     0.4000    1.0000    0.5714         2\n",
      "         187     1.0000    0.5000    0.6667         2\n",
      "         188     1.0000    1.0000    1.0000         2\n",
      "         189     1.0000    0.5000    0.6667         2\n",
      "         190     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.6306       379\n",
      "   macro avg     0.6319    0.5637    0.5617       379\n",
      "weighted avg     0.6836    0.6306    0.6113       379\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "e:\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "e:\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "e:\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "e:\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "e:\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# 加载最好的模型\n",
    "model.load_state_dict(torch.load(r'E:\\ZLJ_code\\yt-url-har-pcap\\data\\model\\model_p100.pth'))\n",
    "# model = model.cuda()\n",
    "\n",
    "model.eval()  # 设置模型为评估模式\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for data in dataset.train_dataloader:\n",
    "    img, label = data\n",
    "    if True:\n",
    "        # img = img.cuda()\n",
    "        # label = label.cuda()\n",
    "        ...\n",
    "    with torch.no_grad():\n",
    "        out = model(img)\n",
    "    _, pred = torch.max(out, 1)\n",
    "    y_true.extend(label.cpu().numpy())\n",
    "    y_pred.extend(pred.cpu().numpy())\n",
    "\n",
    "# 生成分类报告\n",
    "report = classification_report(y_true, y_pred, output_dict=True)\n",
    "\n",
    "# 获取f1-score的macro avg和accuracy\n",
    "f1_score_macro_avg = report['macro avg']['f1-score']\n",
    "accuracy = report['accuracy']\n",
    "\n",
    "\n",
    "# 输出混淆矩阵和分类报告\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_true, y_pred, digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "metadata": {
   "interpreter": {
    "hash": "11f1dc213e07634baa4c5c321dec03c05dafae643c50f20e6d1a492290c05dc2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
